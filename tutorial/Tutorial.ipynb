{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 1\n",
    "\n",
    "##Imports\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "## Data loading and data splitting functions\n",
    "\n",
    "# read the csv file and return a dataframe\n",
    "def data_read_df():\n",
    "    d = {'f1': [10,20,30,40,50],\n",
    "         'f2':[5,10,15,20,25],\n",
    "         'f3': ['a','a','b','b','a'],\n",
    "         'f4': ['x','x','x','y','y'],\n",
    "         'f5': ['Alice','Bob','Claire','Alice','Bob'],\n",
    "         'target': [1,1,1,0,0]}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "def data_split_train_and_test(df, test_size):\n",
    "    sss = StratifiedShuffleSplit(n_splits=2, test_size=test_size, random_state=0)\n",
    "\n",
    "    y = df['target']\n",
    "    for train_index, test_index in sss.split(df, y):\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "    y_train = X_train['target']\n",
    "    y_test = X_test['target']\n",
    "    X_train = X_train.drop(columns=['target'])\n",
    "    X_test = X_test.drop(columns=['target'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Visualiztion functions\n",
    "\n",
    "\n",
    "def visual_generate_bar_char_plot(df, feature_name):\n",
    "    if len(df[feature_name].unique()) > 20:\n",
    "        g = sns.FacetGrid(df, aspect=4)\n",
    "    else:\n",
    "        g = sns.FacetGrid(df, aspect=2)\n",
    "    g.map(sns.countplot, feature_name, order=list(\n",
    "        df[feature_name].value_counts().index))\n",
    "    g.set_xticklabels(rotation=80)\n",
    "    g.set_ylabels(\"count\")\n",
    "\n",
    "\n",
    "def visual_generate_category_target_prob_plot(df, feature_name):\n",
    "    if len(df[feature_name].unique()) > 20:\n",
    "        x = df[feature_name]\n",
    "        g = sns.catplot(x=feature_name, y=\"target\", data=df,\n",
    "                        kind=\"bar\", palette=\"muted\", order=list(df[feature_name].value_counts().index), aspect=4)\n",
    "    else:\n",
    "        g = sns.catplot(x=feature_name, y=\"target\", data=df,\n",
    "                        kind=\"bar\", palette=\"muted\", order=list(df[feature_name].value_counts().index), aspect=1)\n",
    "    g.set_xticklabels(rotation=80)\n",
    "    g.set_ylabels(\"Prob. for target 1\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "\n",
    "def visual_generate_dis_plot(df, feature_name):\n",
    "    g = sns.FacetGrid(df, col='target', aspect=1)\n",
    "    g = g.map(sns.distplot, feature_name)\n",
    "    \n",
    "## Training Functions\n",
    "\n",
    "def train_model(ml_algo, df_train, y_train, params=None):   \n",
    "    ''' \n",
    "    ml_algo options: \n",
    "        'LogisticRegression' / 'DecisionTree' / 'KNN' / 'RandomForest' / 'MultinomialNB' / 'GaussianNB'\n",
    "    '''\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    if ml_algo == 'LogisticRegression':\n",
    "        if 'multi_class' not in params:\n",
    "            params['multi_class'] = 'auto'\n",
    "        if 'solver' not in params:\n",
    "            params['solver'] = 'liblinear'\n",
    "        classifier = LogisticRegression(**params)\n",
    "    elif ml_algo == 'DecisionTree':\n",
    "        classifier = DecisionTreeClassifier(**params)\n",
    "    elif  ml_algo == 'KNN':\n",
    "        classifier = KNeighborsClassifier(**params)\n",
    "    elif ml_algo == 'RandomForest':\n",
    "        if 'n_estimators' not in params:\n",
    "            params['n_estimators'] = 100\n",
    "        classifier = RandomForestClassifier(**params)\n",
    "    elif ml_algo == 'MultinomialNB':\n",
    "        classifier = MultinomialNB()\n",
    "    elif ml_algo == 'GaussianNB':\n",
    "        classifier = GaussianNB()\n",
    "    else:\n",
    "        raise(Exception(\"\"\"The value of the ml-algo parameter should be one of the following:\n",
    "                            LogisticRegression / DecisionTree / KNN / RandomForest / MultinomialNB / GaussianNB\"\"\"))\n",
    "    \n",
    "    classifier.fit(df_train, y_train)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "## Evaluation functions\n",
    "\n",
    "def eval_get_cm(classifier, X, y):\n",
    "    cmtx = pd.DataFrame(\n",
    "        confusion_matrix(classifier.predict(X), y),\n",
    "        index=['pred:0', 'pred:1'],\n",
    "        columns=['true:0', 'true:1']\n",
    "    )\n",
    "    return cmtx\n",
    "\n",
    "def eval_get_score(classifier, X, y, metric):\n",
    "    if metric == 'f1' or metric == 'auc':\n",
    "        if (len(y_test.unique())) > 2 :\n",
    "            raise(Exception('You cannot use the metric \\'{}\\' for multiclass classification tasks'.format(metric)))\n",
    "    '''\n",
    "    metric options:\n",
    "        'precision' / 'recall' / 'accuracy' / 'auc' / 'f1'\n",
    "    '''\n",
    "    if metric == 'accuracy':\n",
    "        return accuracy_score(y, classifier.predict(X), normalize=True)\n",
    "    elif metric == 'f1':\n",
    "        return f1_score(y, classifier.predict(X))\n",
    "    elif metric == 'precision':\n",
    "        from sklearn.metrics import precision_score\n",
    "        return precision_score(y, classifier.predict(X))\n",
    "    elif metric == 'recall':\n",
    "        from sklearn.metrics import recall_score\n",
    "        return recall_score(y, classifier.predict(X))\n",
    "    elif metric == 'auc':\n",
    "        predictions_proba = classifier.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, t = roc_curve(y, predictions_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    else:\n",
    "        raise(Exception(\"\"\"The value of the metric parameter sholud be one of the following:\n",
    "                            precision / recall / accuracy / auc / f1\"\"\"))\n",
    "    return roc_auc\n",
    "\n",
    "def eval_plot_roc_curve(classifier, X, y):\n",
    "    if (len(y_test.unique())) > 2:\n",
    "        raise(Exception('You cannot use this function for multiclass classification tasks'))\n",
    "    # predict probabilities\n",
    "    y_pred_prob = classifier.predict_proba(X)\n",
    "\n",
    "    fpr, tpr, t = roc_curve(y, y_pred_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig1 = plt.figure(figsize=[12, 12])\n",
    "    ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3,\n",
    "             label='AUC = ' + str(round(roc_auc, 2)))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def eval_get_predictions(classifier, X, y):\n",
    "    predictions = classifier.predict(X)\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {'example_index': list(X.index), 'Pred': list(predictions), 'True_value': list(y)}).set_index('example_index')\n",
    "    return predictions_df\n",
    "\n",
    "def get_predictions_proba(classifier, X, y):\n",
    "    predictions = [round(pred,3) for pred in list(classdier.predict_proba(X)[:,1])]\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {'example_index': list(X.index), 'pred': predictions, 'True_value': list(y)}).set_index('example_index')\n",
    "    return predictions_df\n",
    "\n",
    "## Feature engineering (FE) functions\n",
    "\n",
    "def FE_encode_values_of_categorical_features(df, columns_to_encode):\n",
    "\n",
    "    df_to_return = df.copy()\n",
    "    le = LabelEncoder()\n",
    "    for col in columns_to_encode:\n",
    "        df_to_return[col] = le.fit_transform(df_to_return[col])\n",
    "    return df_to_return\n",
    "\n",
    "def FE_create_one_hot_encodeing(df, columns_to_encode):\n",
    "\n",
    "    for x in columns_to_encode:\n",
    "        df = pd.concat([df, pd.get_dummies(df[x], prefix=x)], axis=1)\n",
    "        \n",
    "    df = df.drop(columns = columns_to_encode)\n",
    "    return df\n",
    "\n",
    "\n",
    "def FE_divide_numeric_feature_to_ranges(df, column_to_divide_to_ranges, number_of_ranges):\n",
    "\n",
    "    df_to_return = df.copy()\n",
    "    df_to_return[column_to_divide_to_ranges] = pd.cut(df_to_return[column_to_divide_to_ranges], number_of_ranges)\n",
    "    \n",
    "    return df_to_return\n",
    "\n",
    "## Feature Scaling Functions\n",
    "\n",
    "def feature_scaling(X_train, X_test, columns_to_scale, scaler_method):\n",
    "\n",
    "    X_train_to_return = X_train.copy()\n",
    "    X_test_to_return = X_test.copy()\n",
    "    \n",
    "    if scaler_method == 'Normalizer':\n",
    "        scaler = Normalizer()\n",
    "    elif scaler_method == 'StandardScaler':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_method == 'MinMaxScaler':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise(Exception(\"\"\"The value of the scaling_method parameter sholud be one of the following:\n",
    "                            Normalize / StandardScaler / MinMaxScaler\"\"\"))\n",
    "    \n",
    "    for column in columns_to_scale:\n",
    "        X_train_to_return[column] = X_train_to_return[column].astype(float)\n",
    "        X_test_to_return[column] = X_test_to_return[column].astype(float)\n",
    "    \n",
    "    X_train_to_return[columns_to_scale] = scaler.fit_transform(X_train_to_return[columns_to_scale])\n",
    "    X_test_to_return[columns_to_scale] = scaler.transform(X_test_to_return[columns_to_scale])\n",
    "    \n",
    "    return X_train_to_return, X_test_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API describes a set of functions that will assist you in the development of the predictive model. Using these functions will save you a lot of time!\n",
    "\n",
    "The functions are divided into several categories:\n",
    "<font color='blue'>\n",
    "* Data Loading and Data Splitting Functions\n",
    "* Visualization Functions\n",
    "* Feature Engineering (FE) Functions\n",
    "* Feature Scaling Functions\n",
    "* Training Functions\n",
    "* Evaluation Functions\n",
    "</font>\n",
    "\n",
    "Each section in this Notebook reviews a separate function set.\n",
    "\n",
    "We will begin with the Data Loading and Data Splitting functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Data Splitting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions in this set:\n",
    "<font color='blue'>\n",
    " * data_read_df() : df\n",
    " * data_split_train_and_test(df, test_size) : X_train, y_train, X_test, y_test\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin with `data_read_df()`.\n",
    "\n",
    "The purpose of this function is to import the task's dataset to a DataFrame object.\n",
    "\n",
    "**Exercise**: Set df to the `returned value from data_read_df()` in the cell below and run the cells bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "df = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/data_read_df.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to use `data_split_train_and_test(df, test_size) : X_train, X_test, y_train, y_test`.\n",
    "This function receives a DataFrame and test_size and returns 2 DataFrames (X_train and X_test) and 2 Series (y_train, y_test) \n",
    "\n",
    "**Exercise**: Set X_train, X_test, y_train and y_test to the returned value from `data_split_train_and_test(df, test_size)` while `df is df from the previous exercise` and `test_size is 0.3`. Then, run the cells bellow to display the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "X_train, X_test, y_train, y_test = so\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "display('X_train =') \n",
    "display(X_train)\n",
    "display('X_test =') \n",
    "display(X_test)\n",
    "display('y_train =') \n",
    "display(y_train)\n",
    "display('y_test =') \n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br><br><br><br><br><br>\n",
    "**Expected output**:\n",
    "<img src=\"images/data_split_train_and_test.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of functions includes three functions:\n",
    "<font color='blue'>\n",
    " * visual_generate_bar_chart_plot(df, feature_name) : plot\n",
    " * visual_generate_category_target_prob_plot(df, feature_name) : plot\n",
    " * visual_generate_dis_plot(df, feature_name) : plot\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Generate 3 plots for the DataFrame `df`. `bar chart` and `target prob plot` for the feature `f3` and `distribution (dis)` for the feature `f1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br><br><br><br>\n",
    "**Expected output**:\n",
    "<img src=\"images/visualization.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering (FE) functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four functions in this set:\n",
    "<font color='blue'>\n",
    " * FE_encode_values_of_categorical_features(df, columns_to_encode) : df\n",
    " * FE_create_one_hot_encodeing(df, columns_to_encode) : df\n",
    " * FE_divide_numeric_feature_to_ranges(df, column_to_divide_to_ranges, number_of_ranges) : df\n",
    " * FE_feature_scaling(X_train, X_test, features_to_scale, scaler_method) : df\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall begin with `FE_encode_values_of_categorical_features`.\n",
    "The purpose of this function is to encode (replace strings with numbers) the values of a categorical feature.\n",
    "\n",
    "The function receives `DataFrame` and `columns to encode (list of features' names)` as input and returns a `new DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Encode the values of `f3`, `f4` of `df` and assign the resulting DataFrame to `df_encoded_values`, then run the cells below to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "columns_to_encode = []\n",
    "df_encoded_values = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_encoded_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/FE_encode_values_of_catagorial_features.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now encode the values of `f5` using `one-hot-encoding`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Encode the values of `f5` in `df_encoded_values` using the `FE_create_one_hot_encodeing` method and assign the resulting DataFrame to `df_encoded_values2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "columns_to_encode = []\n",
    "df_encoded_values2 = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_encoded_values2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/FE_create_one_hot_encodeing.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now try to use the `FE_divide_numeric_feature_to_ranges` function. This function divides the values of continuous features into ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Divide the values of `f1` of `df_encoded_values2` into `three` ranges and assign the resulting DataFrame to `df_encoded_values_and_ranges_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "df_encoded_values_and_ranges_values = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_encoded_values_and_ranges_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/FE_divide_continious_feature_to_ranges.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue to the next section, we would like you to encode the values of `f1` in `df_encoded_values_and_ranges_values` and then split the resulting DataFrame into train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Encode the values of `f1` in `df_encoded_values_and_ranges_values` using `FE_encode_values_of_categorical_features` and assign the returned DataFrame to `df_encoded_values_and_ranges_values2`, then run the cell to explore the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 2 line of code)\n",
    "columns_to_encode = []\n",
    "df_encoded_values_and_ranges_values2 = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df_encoded_values_and_ranges_values2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hide_input": true
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/FE_divide_continious_feature_to_ranges2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Split `df_encoded_values_and_ranges_values2` into train and test (test size = 0.3), assign the returned values to `X_train`, `X_test`, `y_train`, `y_test`, and run the cells below.\n",
    "\n",
    "Use the following function:\n",
    "`data_split_train_and_test(df, test_size) : X_train, X_test, y_train, y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "X_train, X_test, y_train, y_test = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "display('X_train =') \n",
    "display(X_train)\n",
    "display('X_test =') \n",
    "display(X_test)\n",
    "display('y_train =') \n",
    "display(y_train)\n",
    "display('y_test =') \n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br><br><br><br><br><br>\n",
    "**Expected output**:\n",
    "<img src=\"images/split_train_and_test2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section only includes a single function which scales the values of continuous variables:\n",
    "\n",
    "`feature_scaling(X_train, X_test, columns_to_scale, scaler_method): X_train, X_test`\n",
    "\n",
    "The function's input is `DataFrame`, `columns' names for scaling their values` and `scaling method` (str). The returned values are new X_train and X_test.\n",
    "\n",
    "The `scaling method` should be one of the following:\n",
    "<font color='blue'>\n",
    " * 'Normalizer'\n",
    " * 'StandardScaler'\n",
    " * 'MinMaxScaler'\n",
    "</font>\n",
    "For more information about these methods, you can google the name of the method and sklearn keyword (e.g. sklearn StandardScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Scale the values of `f2` in `X_train` and `X_test` using the `StandardScaler` scaling method and assign the returned values to `X_train` and `X_test` (overwrite their values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "columns_to_scale = []\n",
    "X_train, X_test = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "display('X_train =')\n",
    "display(X_train)\n",
    "display('X_test =')\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br><br>\n",
    "**Expected output**:\n",
    "<img src=\"images/scaling.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section only includes a single function:\n",
    "\n",
    "`train_model(ml_algo, df_train, y_train, params=None): classifier`\n",
    "\n",
    "The function receives `name of a machine learning algorithm`, `parameters for the algorithm` (if not given, it will use the default Sklearn parameters), the `train’s examples` and `targets` as inputs, and returns a `trained classifier` (after fitting it to train).\n",
    "\n",
    "The `ml-algo` parameter sholud be one of the following:\n",
    "<font color='blue'>\n",
    " * 'LogisticRegression’\n",
    " * 'DecisionTree'\n",
    " * 'KNN'\n",
    " * 'RandomForest'\n",
    " * 'MultinomialNB'\n",
    " * 'GaussianNB'\n",
    "</font>\n",
    "\n",
    "Example of `params` parameter:\n",
    "\n",
    "To use `l2` for `penalty` and `C=1` to train `LogisticRegression`, you can send the `params` varaiable to the function as follows:\n",
    "\n",
    "params = {\n",
    "    'penalty' = 'l2'\n",
    "    'C' = 1\n",
    "}\n",
    "\n",
    "**For more information about the optional parameters, you can google the name of the ML algorithm and the sklearn keyword (e.g. sklearn LogisticRegression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Train a LogisticRegression classifier using the `default parameters` and `X_train` and `y_train` for fitting. Assign the returned value to a variable called `classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "classifier = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last set of functions is `Evaluation`. The purpose of these functions is to evaluate your model on a test set.\n",
    "\n",
    "It includes five functions, but we will only practice two functions because the all five functions work on very similar principles.\n",
    "\n",
    "\n",
    "Here is the entire list of `evaluation` functions:\n",
    "\n",
    "<font color='blue'>\n",
    "    \n",
    " * eval_get_score(classifier, X, y, metric) : score (Float)\n",
    "    \n",
    " * eval_get_cm(classifier, X, y) : cm (DataFrame)\n",
    " \n",
    " * eval_get_predictions(classifier, X, y) : predictions (DataFrame)\n",
    " \n",
    " * eval_get_predictions_proba(classifier, X, y) : predictions (DataFrame)\n",
    " \n",
    " * eval_plot_roc_curve(classifier, X, y): plot a grpah\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin with eval_get_score(classifier, X, y, metric).\n",
    "\n",
    "This function recieves `trained classifier`, `X (examples to predict)`, `y (target values of X)` and `metric` as inputs.\n",
    "\n",
    "metric should be one of the following:\n",
    "<font color='blue'>\n",
    "    \n",
    " * 'precision'\n",
    "    \n",
    " * 'recall'\n",
    "\n",
    " * 'accuracy'\n",
    " \n",
    " * 'auc'\n",
    "\n",
    " * 'f1'\n",
    " \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Calculate the accuracy for `X_test` and `y_test` when using the `classifier` you trained in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "accuracy = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "Accuracy: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: print the predictions for `X_test` when using the `classifier` you trained in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "predictions_df = None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "**Expected output**:\n",
    "<img src=\"images/eval_get_predictions.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"http://localhost:8889/notebooks/Dropbox%20(BGU)/Expert%20vs%20Novices%20Experiment/Adult%20Experiment.ipynb\">Link to start the experiment</a></center>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
